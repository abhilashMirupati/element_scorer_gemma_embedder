# -*- coding: utf-8 -*-
"""LLM_Powered_Elem_Selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17b-W79owvpWXIJ82u07w0Tv8YIq5fncx
"""

# ============================
# 📦 Install dependencies
# ============================
!pip -q install playwright nest_asyncio langchain langchain-community langchain-google-genai google-generativeai huggingface_hub langchain-huggingface
!python -m playwright install --with-deps chromium
!pip -q install lxml

# ============================
# 📚 Imports
# ============================
import asyncio, time, os
from typing import Any, Dict, List, Optional, Tuple
from lxml import html
import re
import nest_asyncio
nest_asyncio.apply()
from playwright.async_api import async_playwright

# LangChain imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.chat_models import ChatOllama, ChatOpenAI
from langchain.schema import HumanMessage

def _run(coro):
    return asyncio.get_event_loop().run_until_complete(coro)

def build_snippet(rec: Dict[str,Any]) -> str:
    return f"""
Node: {rec['nodeHTML'][:300]}...
Parent: {rec['parentHTML'][:200]}...
Grandparent: {rec['grandHTML'][:200]}...
Visible: {rec['visible']}
"""

_JS_INPUTS = r"""
() => {
  const matches = [];
  const walker = document.createTreeWalker(document.body, NodeFilter.SHOW_ELEMENT, null, false);
  let node;
  while (node = walker.nextNode()) {
    try {
      const tag = (node.tagName || "").toLowerCase();
      if (["input","textarea"].includes(tag)) {
        const type = (node.getAttribute("type") || "").toLowerCase();
        // Skip noisy input types, tag is input but we will not be able to enter text.
        if (["hidden","checkbox","radio","file","range","color"].includes(type)) continue;
        matches.push(node);
      }
    } catch(e) {}
  }
  const finals = matches.filter(el => !matches.some(other => other !== el && el.contains(other)));
  return finals.map(el => {
    function outer(n) { return n ? n.outerHTML : ""; }
    return {
      nodeHTML: outer(el),
      parentHTML: outer(el.parentElement),
      grandHTML: outer(el.parentElement ? el.parentElement.parentElement : null),
      visible: el.offsetParent !== null
    };
  });
}
"""




# ============================
# 🧩 Extraction helpers for inputs
# ============================
async def _grab_inputs_async(url: str,
                             wait_until: str="networkidle", timeout_ms: int=60000) -> List[Dict[str,Any]]:
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url, wait_until=wait_until, timeout=timeout_ms)
        results=[]
        for fr in page.frames:
            try:
                res = await fr.evaluate(_JS_INPUTS)
                if res: results.extend(res)
            except Exception as e:
                print("Frame error:", e)
        await browser.close()
    return results

def clean_html(html: str) -> str:
    # Collapse multiple newlines/spaces but keep tag/attr spacing
    return " ".join(html.split())

def build_snippet(rec: Dict[str, Any]) -> str:
    return f"""
Node: {clean_html(rec['nodeHTML'])[:300]}...
Parent: {clean_html(rec['parentHTML'])[:200]}...
Grandparent: {clean_html(rec['grandHTML'])[:200]}...
Visible: {rec['visible']}
"""

# ============================
# 🚀 Main pipeline for inputs
# ============================
URL         = "https://www.verizon.com/smartphones/"


# 1. Extract exact matches
start_time = time.time()
raw_inputs = _run(_grab_inputs_async(URL, wait_until="domcontentloaded"))
print(f"extracted raw_inputs as  {raw_inputs}")
#raw = _run(_grab_exact_async(URL, TARGET_TEXT, wait_until="domcontentloaded", timeout_ms=120000))
end_time = time.time()
print(f"Extracted {len(raw_inputs)} candidates in {end_time - start_time:.2f} seconds")

# 2. Build snippets
start_time = time.time()
snippets = [build_snippet(r) for r in raw_inputs]
end_time = time.time()
print(f"Built {len(snippets)} snippets in {end_time - start_time:.2f} seconds")

for i,s in enumerate(snippets, start=1):
    print(f"\n--- Candidate {i} ---\n{s}")


#To filter visbile: true
# snippets = [build_snippet(r) for r in raw if r['visible']]
#Visible: True = on the page layout, regardless of whether you scrolled.
#Visible: False = literally hidden from layout (style = display:none, visibility:hidden, etc.).

# ============================
# 🕷️ JavaScript: innerText first → CSS attribute fallback (with name fast-path)
# ============================
_JS_EXACT = r"""
(targetText) => {
  const out  = n => n ? n.outerHTML : "";
  const vis  = el => !!(el && el.offsetParent !== null);
  const uniq = nodes => {
    const s = new Set(), a = [];
    nodes.forEach(n => { if (n && !s.has(n)) { s.add(n); a.push(n); }});
    // remove parent if a child is already included
    return a.filter(el => !a.some(other => other !== el && other.contains(el)));
  };

  // normalize: trim, collapse spaces, map NBSP/ZW spaces to ' '
  const norm = s => String(s ?? "")
    .replace(/[\u00A0\u2000-\u200B\u202F\u205F\u3000]/g, " ")
    .replace(/\s+/g, " ")
    .trim();

  const RAW = norm(targetText);
  if (!RAW) return [];

  // ---------- Phase 1: original innerText scan (fast path) ----------
  const txtMatches = [];
  const walker = document.createTreeWalker(document.body, NodeFilter.SHOW_ELEMENT, null, false);
  let node;
  while ((node = walker.nextNode())) {
    try {
      if (norm(node.innerText || "") === RAW) txtMatches.push(node);
    } catch (_) {}
  }
  if (txtMatches.length > 0) {
    const finals = uniq(txtMatches);
    return finals.map(el => ({
      nodeHTML: out(el),
      parentHTML: out(el.parentElement),
      grandHTML: out(el.parentElement ? el.parentElement.parentElement : null),
      visible: vis(el)
    }));
  }

  // ---------- Phase 2: attribute fallback via CSS selectors ----------
  const cssEscape = (s) =>
    (window.CSS && CSS.escape)
      ? CSS.escape(s)
      : String(s).replace(/[\\^$*+?.()|[\]{}"'`]/g, "\\$&");

  let attrMatches = [];

  try {
    // FAST PATHS (O(1) native lookups)
    // id
    const byId = document.getElementById(RAW);
    if (byId) attrMatches.push(byId);

    // name (this is the key fix for your case)
    const byName = document.getElementsByName ? document.getElementsByName(RAW) : [];
    if (byName && byName.length) attrMatches.push(...byName);

    // If fast paths already found something, we can format & return
    if (attrMatches.length > 0) {
      const finals = uniq(attrMatches);
      return finals.map(el => ({
        nodeHTML: out(el),
        parentHTML: out(el.parentElement),
        grandHTML: out(el.parentElement ? el.parentElement.parentElement : null),
        visible: vis(el)
      }));
    }

    // Curated CSS selector pass (light DOM)
    const q = cssEscape(RAW);
    const selector = [
      // stable/common ids & names
      `[id="${q}"]`,
      `[name="${q}"]`,
      `input[name="${q}"]`,
      `textarea[name="${q}"]`,
      `select[name="${q}"]`,

      // ARIA & role hooks
      `[role="${q}"]`,
      `[aria-label="${q}"]`,
      `[aria-labelledby="${q}"]`,
      `[aria-describedby="${q}"]`,

      // classic title/alt
      `[title="${q}"]`,
      `[alt="${q}"]`,

      // placeholders (inputs/textareas)
      `input[placeholder="${q}"]`,
      `textarea[placeholder="${q}"]`,

      // testing-friendly stable data hooks
      `[data-testid="${q}"]`,
      `[data-test="${q}"]`,
      `[data-qa="${q}"]`,
      `[data-automation-id="${q}"]`,
      `[data-id="${q}"]`,

      // label 'for' linkage
      `[for="${q}"]`,
      `label[for="${q}"]`,

      // input buttons by value (no innerText)
      `input[type="button"][value="${q}"]`,
      `input[type="submit"][value="${q}"]`,
      `input[type="reset"][value="${q}"]`
    ].join(",");

    attrMatches = Array.from(document.querySelectorAll(selector));
  } catch (_) { attrMatches = []; }

  // ---------- Phase 2b: Shadow/whitespace-safe fallback (only if CSS found nothing) ----------
  if (attrMatches.length === 0) {
    try {
      const ATTR_KEYS = [
        "id","name","role",
        "aria-label","aria-labelledby","aria-describedby",
        "title","alt",
        "data-testid","data-test","data-qa","data-automation-id","data-id",
        "for","placeholder","value"
      ];

      const stack = [document];
      while (stack.length) {
        const root = stack.pop();
        const all = (root.querySelectorAll ? root.querySelectorAll("*") : []);
        for (const el of all) {
          if (el.shadowRoot) stack.push(el.shadowRoot);

          for (const k of ATTR_KEYS) {
            if (k === "placeholder") {
              const tg = (el.tagName || "").toLowerCase();
              if ((tg === "input" || tg === "textarea") && norm(el.getAttribute("placeholder")) === RAW) {
                attrMatches.push(el); break;
              }
              continue;
            }
            if (k === "value") {
              const tg = (el.tagName || "").toLowerCase();
              if (tg === "input") {
                const t = (el.getAttribute("type") || "").toLowerCase();
                if ((t === "button" || t === "submit" || t === "reset") && norm(el.getAttribute("value")) === RAW) {
                  attrMatches.push(el); break;
                }
              }
              continue;
            }
            const v = el.getAttribute && el.getAttribute(k);
            if (v != null && norm(v) === RAW) { attrMatches.push(el); break; }
          }
        }
      }
    } catch (_) {}
  }

  const finals = uniq(attrMatches);
  return finals.map(el => ({
    nodeHTML: out(el),
    parentHTML: out(el.parentElement),
    grandHTML: out(el.parentElement ? el.parentElement.parentElement : null),
    visible: vis(el)
  }));
}
"""

# ============================
# 🧩 Extraction helpers (match original behavior → same 3 nodes)
# ============================
import asyncio
import time
from typing import List, Dict, Any

# NOTE: Your _JS_EXACT (one-arg version) must be defined above.

async def _grab_exact_async(
    url: str,
    target_text: str,
    wait_until: str = "networkidle",   # same as your original
    timeout_ms: int = 60000,
    shorten_text_wait: bool = False,   # set True to clamp the text wait to 300ms
) -> List[Dict[str, Any]]:
    """
    Exact replica of your original frame-scanning behavior:
      - goto(wait_until=networkidle)
      - wait_for_selector(text=...) with *full* timeout by default
      - iterate *all* frames (no same-origin filter, no stability gating)
      - evaluate _JS_EXACT in each; collect all results
    This reproduces the '3 candidates' you saw with your original helper.
    """
    from playwright.async_api import async_playwright

    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url, wait_until=wait_until, timeout=timeout_ms)

        # --- Exact same text wait as your original (unless shortened) ---
        try:
            await page.wait_for_selector(
                f'text="{target_text}"',
                timeout=(300 if shorten_text_wait else timeout_ms)
            )
        except Exception:
            # swallow, just like your original comment
            pass

        results: List[Dict[str, Any]] = []

        # --- Iterate EVERY frame (no filters), just like your original ---
        for fr in page.frames:
            try:
                res = await fr.evaluate(_JS_EXACT, target_text)
                if res:
                    results.extend(res)
            except Exception as e:
                # Your original printed these; keep same behavior
                print("Frame error:", e)

        await browser.close()
        return results


def _run(coro):
    return asyncio.get_event_loop().run_until_complete(coro)


def build_snippet(rec: Dict[str, Any]) -> str:
    return f"""
Node: {rec.get('nodeHTML','')[:300]}...
Parent: {rec.get('parentHTML','')[:200]}...
Grandparent: {rec.get('grandHTML','')[:200]}...
Visible: {rec.get('visible')}
"""

# ============================
# 🤖 LLM Selection (Gemini or Ollama)
# ============================

# Option A: Gemini (needs API key in env)
os.environ["GOOGLE_API_KEY"] = "AIzaSyBeKPmuKklXJAAO4AA_e0oU_gn3Uh_27t8"
gemini_model = ChatGoogleGenerativeAI(model="gemini-1.5-flash")

# Option B: Ollama (local)
ollama_model = ChatOllama(model="gemma3:4b")

#Option C: HuggingFace Inference API
hf_model = ChatOpenAI(
    # Found meta-llama/Llama-3.1-8B-Instruct:novita as alternative choice
    model_name="deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    openai_api_base="https://router.huggingface.co/v1",
    openai_api_key="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",
)
#- Look at tag type, attributes, CSS clues, and ancestor structure.

def ask_llm(query: str, snippets: List[str], use="gemini") -> str:
    numbered = "\n\n".join([f"Candidate {i+1}:\n{snip}" for i,snip in enumerate(snippets)])
    prompt = f"""
You are resolving which HTML snippet best matches the user request.

User query: {query}

Candidates:
{numbered}

Instructions:

1. Prefer elements that are **visible** (`Visible: True`) over invisible ones.
2. Prefer elements that are **interactable** (tags like <button>, <a>, <input>) if the query implies clicking.
3. Match user query words with **element text AND attributes** (id, aria-label, label, href, role).
4. Prefer elements whose **ancestors** give context matching the query (e.g. menus, sections, lists).
5. If multiple candidates look the same, select the one with the **closest, most specific ancestor match**, not just a duplicate sibling.
5. If nothing is a good match, reply with there is no matching Candidate matching to query,  .

- Reply ONLY with "Candidate X"

"""
# and alos give best "xpath" , not absolute but stable relative xpath  like //tag[text()='targetText'].
    if use == "gemini":
        model = gemini_model
    elif use == "hf":
        model = hf_model
    else:
        model = ollama_model
    #print(f"prompt is  {prompt}")
    resp = model.invoke([HumanMessage(content=prompt)])
    return resp.content

# ============================
# 🚀 Main pipeline
# ============================
URL         = "https://www.verizon.com/smartphones/"
QUERY       = 'Click on Compare button for Apple iPhone 15 device'
TARGET_TEXT = "Special Offers"

# 1. Extract exact matches
start_time = time.time()
raw = _run(_grab_exact_async(URL, TARGET_TEXT, wait_until="domcontentloaded", timeout_ms=10000))
end_time = time.time()
print(f"Extracted {len(raw)} candidates in {end_time - start_time:.2f} seconds")
print(f"Extracted raw 1st are {raw[0]}")
#print(f"Extracted raw 1st are {raw[1]}")
# # 2. Build snippets
# start_time = time.time()
snippets = [build_snippet(r) for r in raw]
# end_time = time.time()
print(f"Built {len(snippets)} snippets in {end_time - start_time:.2f} seconds")

for i,s in enumerate(snippets, start=1):
    print(f"\n--- Candidate {i} ---\n{s}")

# # # 3. Ask LLM to decide
# start_time = time.time()
# decision = ask_llm(QUERY, snippets, use="hf")   # or use="ollama"
# end_time = time.time()
# print(f"\nAsked LLM to decide in {end_time - start_time:.2f} seconds")
# print("\n🤖 LLM Decision:", decision)

"""**BELOW IS THE CODE TO USE IMAGE ANALYSIS TO VALIDATE EDGE Q&A SCENARIOS**"""

import base64, io
import requests
from playwright.sync_api import sync_playwright
from PIL import Image
from huggingface_hub import InferenceClient

# ===== CONFIG =====
API_KEY = "AIzaSyAQpkj6XUfKEoIxdQpbYRo5MhtJ5O0UMiU"  # replace with your Gemini API key
ENDPOINT = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
use="hf"


# ============================
# 📸 Capture Screenshot
# ============================
async def capture_screenshot(url, save_path="screenshot.png"):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url, wait_until="networkidle")
        await page.screenshot(path=save_path, full_page=True)
        await browser.close()
    return save_path

# ============================
# 🗜️ Safe Image Encoder
# ============================
def _resize_and_encode(image_path, max_size=(1200, 1200), quality=85):
    """
    Resize + compress image to keep payload small
    but preserve enough clarity for QA models.
    Returns: data URL string "data:image/jpeg;base64,..."
    """
    img = Image.open(image_path).convert("RGB")
    img.thumbnail(max_size)

    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality)
    img_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

    size_kb = len(img_b64) / 1024
    orig_kb = os.path.getsize(image_path) / 1024
    print(f"Compressed image size: {size_kb:.2f} KB (original: {orig_kb:.2f} KB, file={image_path})")
    return f"data:image/jpeg;base64,{img_b64}"



def ask_gemini_with_screenshot(image_path, question):
    with open(image_path, "rb") as f:
        img_b64 = base64.b64encode(f.read()).decode("utf-8")

  # Send text + image
    msg = HumanMessage(content=[
        {"type": "text", "text": question},
        {"type": "image_url",
         "image_url": f"data:image/png;base64,{img_b64}"}
    ])
    response = gemini_model.invoke([msg])
    print(f"response is {response}")
    return response.content

# ============================
# 🤖 Ask HuggingFace Model
# ============================
def ask_hf_inference_with_screenshot(image_path, question):
    """
    Uses InferenceClient to call a vision-language model like Qwen2.5-VL.
    """

    # ============================
    # 🔧 Hugging Face Client
    # ============================
    HF_TOKEN = "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"  # or set in env
    client = InferenceClient(token=HF_TOKEN)


    img_b64_url = _resize_and_encode(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": question},
                {"type": "image_url", "image_url": {"url": img_b64_url}}
            ],
        }
    ]

    #need ot check gemma 4b
    response = client.chat.completions.create(
        model="Qwen/Qwen2.5-VL-7B-Instruct",  # must be VLM
        messages=messages,
        max_tokens=300,
    )

    answer = response.choices[0].message.content
    print(f"Response: {answer}")
    return answer

# ===== Example run =====
url = "https://www.verizon.com/smartphones/apple-iphone-12-certified-pre-owned/"
screenshot_path = _run(capture_screenshot(url))

question = "Can you list Apple iPhone 12 (Certified Pre-Owned) all details under ComCompare devices section"
result = ask_gemini_with_screenshot(screenshot_path, question) if use == "gemini" else ask_hf_inference_with_screenshot(screenshot_path, question)

print("Gemini Answer:", result)

if "yes" in result.lower() or "found" in result.lower():
    print("✅ Validation Passed")
else:
    print("❌ Validation Failed")

"""# **`Code to know when to query`**

---
1. When you call:
await page.evaluate("attachDynamicWatcher(['What are you looking for?'])")


The MutationObserver is armed, but at this exact moment the text "What are you looking for?" is not yet in the DOM.

That’s fine — the observer doesn’t care about the past. It only watches newly added nodes from this point forward.

2. After you click:
await page.click("button#gnav20-search-icon")


The click triggers Verizon’s frontend JS to inject a search input with placeholder "What are you looking for?".

As soon as that node appears in the DOM, the observer fires → it inspects that node’s text/attributes → it finds the phrase → stores it in window.__last_match.

3. When you call:
match1 = await wait_for_match(page)


This polls the browser for window.__last_match.

Since the observer already caught the new node, you now get back "What are you looking for?".

That’s how you know: ✅ DOM changed, time to re-query your snapshot.


 **Easy way to understand how it works**


Think of it like a security guard:

attachDynamicWatcher(["What are you looking for?"]) = You tell the guard: “Call me if you see this phrase appear.”

The guard checks the room immediately (initial scan).

Then the guard watches the door (MutationObserver).
If new people (DOM nodes) walk in, the guard checks if they match.

If one matches, the guard yells: [WATCHER] ⚡ Matched: … and writes it down in a notebook (window.__watcher_state.last_match).

Later, when you ask wait_for_match(), Python just reads the notebook:
✅ “Yes, I saw it” or ❌ “No match”
\
"""

!pip install playwright
!playwright install chromium

import asyncio
from playwright.async_api import async_playwright

MUTATION_OBSERVER_SCRIPT = """
window.__watcher_state = {
  seen: new Set(),
  last_match: null,
  last_step: 0
};

window.attachDynamicWatcher = function(targetTexts, stepId) {
  if (!Array.isArray(targetTexts)) targetTexts = [targetTexts];

  // Reset for new step
  window.__watcher_state.seen.clear();
  window.__watcher_state.last_match = null;
  window.__watcher_state.last_step = stepId;

  function checkNode(node) {
    if (node.nodeType !== 1) return null;
    const text = (node.innerText || "").trim();
    const attrs = Array.from(node.attributes || []).map(a => a.value).join(" ");

    for (const target of targetTexts) {
      if ((text && text.includes(target)) || (attrs && attrs.includes(target))) {
        if (!window.__watcher_state.seen.has(target)) {
          console.log("[WATCHER] ⚡ Matched (step " + stepId + "):", target);
          window.__watcher_state.seen.add(target);
          window.__watcher_state.last_match = { target, step: stepId };
        }
        return target;
      }
    }
    return null;
  }

  console.log("[WATCHER] ✅ Attached for step " + stepId + ": " + targetTexts.join(", "));

  // Initial scan
  document.querySelectorAll("*").forEach(node => checkNode(node));

  // Observe new nodes
  new MutationObserver((mutations) => {
    for (const m of mutations) {
      m.addedNodes.forEach(node => {
        if (checkNode(node)) return;
        if (node.querySelectorAll) {
          node.querySelectorAll("*").forEach(child => checkNode(child));
        }
      });
    }
  }).observe(document, { childList: true, subtree: true });
};

"""

async def wait_for_match(page, timeout=5000):
    """
    Polls for the last_match in window.__watcher_state.
    Returns the matched target string or None.
    """
    try:
        match = await page.wait_for_function(
            """() => {
                if (window.__watcher_state && window.__watcher_state.last_match) {
                    return window.__watcher_state.last_match.target;
                }
                return null;
            }""",
            timeout=timeout
        )
        return await match.json_value()
    except Exception:
        return None

def handle_console(msg):
    text = msg.text
    if "[WATCHER]" in text:   # filter out Verizon's noise
        print("BROWSER:", text)


async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        page.on("console", handle_console)

        # Inject watcher script
        await page.add_init_script(MUTATION_OBSERVER_SCRIPT)

        # Step 1: Click search
        await page.goto("https://www.verizon.com/", wait_until="domcontentloaded")
        await page.evaluate("attachDynamicWatcher(['What are you looking for?'], 1)")
        await page.click("button#gnav20-search-icon")
        match1 = await wait_for_match(page)
        print("Step 1 -> should_requery:", match1 is not None, "| matched:", match1)

        # Step 2
        await page.evaluate("attachDynamicWatcher(['Featured devices'], 2)")
        await page.fill("input#search_box_gnav_input", "iPhone 17")
        match2 = await wait_for_match(page)
        print("Step 2 -> should_requery:", match2 is not None, "| matched:", match2)

        # Step 3
        await page.evaluate("attachDynamicWatcher(['Featured devices'], 3)")
        match3 = await wait_for_match(page)
        print("Step 3 -> should_requery:", match3 is not None, "| matched:", match3)


        await browser.close()

# In Colab, call like this:
await main()
